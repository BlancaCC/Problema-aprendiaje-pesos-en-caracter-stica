%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Algoritmo Greedy 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Algoritmo Greedy}

Con  el fin de reducir el costo computacional 
introducido por el algoritmo anterior vamos a proceder a un algoritmo voraz denominado 
\textit{RELIEF}.

La idea que subyace es la siguiente: ponderaremos los atributos que son relevantes 
para clasificar elementos, es decir aquellos que marquen diferencias entre elementos que clasifiquen igual \textit{amigos} y aquellos que clasifiquen diferente \textit{enemigos}.

\begin{algorithm}[H]
    \caption{Algoritmo RELIEF}
        \hspace*{\algorithmicindent} 
        \textbf{Salida}:
        Vector de pesos $w$.        
    \begin{algorithmic}[1]
      \Procedure{RELIEF}{$datos$,
      $etiquetas$
    }
    \Comment{Almacenamos las distancias y si son de la misma clase}

    \For{ para cada dos pares (atributo, etiqueta)  $(x_i,y_i),(x_j,y_j)$
    tal que $i < j$
    } 
          \State $distancia[i,j] \gets (DistanciaEuclidea(x_i,x_j), y_i == y_j) $ 
    \EndFor

    \Comment{Inicializamos vector que pondera los atributos a cero}
    \State $w \gets vectorDeCeros$ 

    \Comment{Inicializamos variables auxiliares}
    \State $distanciaEnemigo \gets \infty$
    \State $distanciaAmigo \gets \infty$
    \State $indiceEnemigo \gets \emptyset$
    \State $indiceAmigo \gets \emptyset$
    
    \Comment{Encontramos los enemigos y amigos más cercanos }
    \For{ para cada dato del $x_i$ conjunto de entrenamiento 
    } 
        \For{ para cada dato del $x_j$ conjunto de entrenamiento distinto de $x_i$
        } 
            \State $a \gets minimo\{i,j\}$
            \State $b \gets maximo\{i,j\}$

            \Comment{Caso en que son amigos}
            \If{$y_i == y_j$}
                \If{ $distancia[a,b] < distanciaAmigo$ }
                    \State $distanciaAmigo \gets distancia[a,b]$
                    \State $indiceAmigo \gets j$
                \EndIf
            \EndIf
            \Comment{Caso en que son enemigos}
            \If{$y_i \neq y_j$}
                \If{ $distancia[a,b] < distanciaEnemigo$ }
                    \State $distanciaAmigo \gets distancia[a,b]$
                    \State $indiceEnemigo \gets j$
                \EndIf
            \EndIf
            
            \Comment{Añadimos peso a las diferencia entre amigos y enemigos}
            \State $w \gets w + |x_i - x_{indiceAmigo}| + |x_i - x_{indiceEnemigo}|$
        \EndFor
        
        \State $w \gets PonemosValoresNegativosACero(w)$
        \Comment{Truncamos los valores 
        negativos a cero}
        \State $w \gets Reescalamos(w)$
        \Comment{Dividimos cada coeficiente por el máximo}
    \EndFor

    \State \textbf{return} $w$
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}

  Podemos ver como al tener el algoritmo greedy 
una eficiencia $\mathcal{O}(n^2)$, pero de constantes ocultas mucho menores que el algoritmo de búsqueda local. 

\subsection{Los resultados obtenidos han sido los siguientes}


\subsubsection{Ionosphere} 

\begin{table}[H]
  \centering
  \begin{tabular}{|c|c|c|c|c|}
    \hline
    & \multicolumn{4}{|c|}{\textit{Ionosphere}}  \\
    \hline
    &	Clasificación &		Reducción	
    &	Agregación	&	Tiempo en ms \\
    \hline
    Partición 1	&  87.324  &  2.941  &  45.133  &  60.649  \\
    Partición 2 &	 87.143  &  2.941  &  45.042  &  46.026  \\
    Partición 3 &  75.714  &  2.941  &  39.328  &  32.651  \\
    Partición 4	&  84.286  &  2.941  &  43.613  &  61.079 \\
    Partición 5	&  84.286  &  2.941  &  43.613  &  44.848  \\
    \hline
    Medias 	 &  83.751  &  2.941  &  43.346  &  49.051 \\
    \hline
    Desviación típica &	 4.728  &  0.0  &  2.364  &  11.989  \\ 
    \hline  
  \end{tabular}
  \caption{Resultados búsqueda greedy para los datos \textbf{ionosphere}}
  \label{table:greedy_ionosphere}
\end{table}

Se han analizado a demás los pesos resultantes de cada partición, obteniendo con ello: 
Un vector de pesos medio con un redondeo de tres decimales es 

\begin{align*}
w_{medio} = [  
&  0.285, 0.0, 0.343, 0.355, 0.321, 0.482, 0.44, 0.974, 0.577, 0.471, 0.621, 0.544, 0.841, 0.706  \\
&  0.706, 0.842, 0.515, 0.919, 0.467, 0.848, 0.546, 0.915, 0.652, 0.801, 0.574, 0.767, 0.477, 0.604  \\
&  0.604, 0.572, 0.72, 0.485, 0.772, 0.537, 0.744, 0.573 
 ]
\end{align*}

Donde cada coeficiente del vector presenta una desviación típica media de 

\begin{align*}
  w_{desv. tip.} = [ 
    &  0.085, 0.0, 0.048, 0.027, 0.059, 0.011, 0.012, 0.058, 0.127, 0.104, 0.083, 0.029, 0.031, 0.01  \\
    &  0.01, 0.065, 0.08, 0.045, 0.03, 0.085, 0.031, 0.037, 0.016, 0.016, 0.139, 0.051, 0.058, 0.026  \\
    &  0.026, 0.08, 0.041, 0.117, 0.038, 0.099, 0.002, 0.077 
   ]
  \end{align*}

  La media de de las coeficientes de la desviación típica es de $0.053$, esto es un valor bastante bueno y significa que solemos converger a soluciones de $w$ similares. 
  Observemos además que podemos reducir un atributo, el segundo con bastante certeza, ya que por su desviación típica vemos que siempre se reduce. 




  \subsubsection{Parkinsons} 

  \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
      \hline
      & \multicolumn{4}{|c|}{\textit{Parkinsons}}  \\
      \hline
      &	Clasificación &		Reducción	
      &	Agregación	&	Tiempo en ms \\
      \hline
      Partición 1	&    94.872  &  0.0  &  47.436  &  17.603   \\
      Partición 2 &	   100.0  &  0.0  &  50.0  &  7.515   \\
      Partición 3 &    94.872  &  0.0  &  47.436  &  17.254    \\
      Partición 4	&    92.308  &  0.0  &  46.154  &  17.297  \\
      Partición 5	&    94.872  &  0.0  &  47.436  &  7.449   \\
      \hline
      Medias 	 &    95.385  &  0.0  &  47.692  &  13.424   \\
      \hline
      Desviación típica &	   2.809  &  0.0  &  1.404  &  5.426   \\ 
      \hline  
    \end{tabular}
    \caption{Resultados búsqueda greedy para los datos \textbf{Parkinson}}
    \label{table:greedy_parkinson}
  \end{table}
  
  Se han analizado a demás los pesos resultantes de cada partición, obteniendo con ello: 
  Un vector de pesos medio con un redondeo de tres decimales es 
  El vector de pesos medio es 

\begin{align*}
  w_{medio} = [ 
    & 0.601, 0.347, 0.659, 0.346, 0.257, 0.317, 0.323, 0.316, 0.462, 0.424, 0.538, 0.422, 0.35, 0.538 \\
    & 0.538, 0.225, 0.558, 0.979, 0.675, 0.528, 0.695, 0.681, 0.521]
  \end{align*}
  
  Donde cada coeficiente del vector presenta una desviación típica media de 
  
  \begin{align*}
    w_{desv. tip.} = [ 
      & 0.029, 0.019, 0.191, 0.051, 0.002, 0.061, 0.05, 0.061, 0.082, 0.088, 0.098, 0.079, 0.07, 0.098 \\
      & 0.098, 0.03, 0.086, 0.048, 0.145, 0.031, 0.057, 0.179, 0.003
     ]
\end{align*}

El valor de peso medio es de $0.891$ y la desviación típica de $0.181$, luego por media todos los pesos son por lo general relevantes. 

Además la media de las desviaciones típicas es de $0.071$ lo que indica que se converge con gran robustez a la misma solución.



\subsubsection{Spectf Heart} 

\begin{table}[H]
  \centering
  \begin{tabular}{|c|c|c|c|c|}
    \hline
    & \multicolumn{4}{|c|}{\textit{Spectf Heart}}  \\
    \hline
    &	Clasificación &		Reducción	
    &	Agregación	&	Tiempo en ms \\
    \hline
    Partición 1	&    84.286  &  0.0  &  42.143  &  63.055    \\
    Partición 2 &	  80.0  &  0.0  &  40.0  &  55.255    \\
    Partición 3 &       80.0  &  0.0  &  40.0  &  44.498     \\
    Partición 4	&      90.0  &  0.0  &  45.0  &  62.065    \\
    Partición 5	&     85.507  &  0.0  &  42.754  &  55.167    \\
    \hline
    Medias 	 &    83.959  &  0.0  &  41.979  &  56.008   \\
    \hline
    Desviación típica &	   4.194  &  0.0  &  2.097  &  7.418    \\ 
    \hline  
  \end{tabular}
  \caption{Resultados búsqueda greedy para los datos \textbf{Spectf Heart}}
  \label{table:greedy_Spectf Heart}
\end{table}

Se han analizado a demás los pesos resultantes de cada partición, obteniendo con ello: 
Un vector de pesos medio con un redondeo de tres decimales es 
El vector de pesos medio es 

\begin{align*}
w_{medio} = [ 
    &   0.589, 0.953, 0.587, 0.782, 0.562, 0.656, 0.407, 0.609, 0.455, 0.641, 0.416, 0.513, 0.586, 0.643  \\
    &  0.643, 0.614, 0.592, 0.458, 0.484, 0.689, 0.537, 0.406, 0.526, 0.556, 0.651, 0.822, 0.832, 0.727  \\
    &  0.727, 0.669, 0.736, 0.898, 0.614, 0.343, 0.502, 0.555, 0.517, 0.536, 0.697, 0.59, 0.537, 0.77  \\
    &  0.77, 0.592, 0.709, 0.738, 0.903]
\end{align*}

Donde cada coeficiente del vector presenta una desviación típica media de 

\begin{align*}
  w_{desv. tip.} = [ 
    &  0.039,0.105, 0.01, 0.088, 0.0, 0.034, 0.016, 0.065, 0.072, 0.09, 0.094, 0.03, 0.085, 0.199  \\
    &  0.199, 0.021, 0.008, 0.08, 0.064, 0.095, 0.059, 0.053, 0.012, 0.157, 0.109, 0.179, 0.122, 0.214  \\
    &  0.214, 0.129, 0.014, 0.041, 0.133, 0.019, 0.087, 0.019, 0.067, 0.058, 0.091, 0.002, 0.048, 0.028  \\
    &  0.028, 0.06, 0.037, 0.12, 0.023 
   ]
\end{align*}

El valor de peso medio es de $0.618$ y la desviación típica de $0.139$, luego por media todos los pesos son por lo general relevantes. 

Además la media de las desviaciones típicas es de $0.070$ lo que indica que se converge con gran robustez a la misma solución.

\subsubsection*{Reflexiones}

Como podemos observar la reducción ha sido prácticamente nula, esto es algo totalmente 
normal ya que no se ha tenido en cuenta durante el diseño del algoritmo.

Volviendo a utilizar las comparativas de tiempo 
de acorde a la métrica (\ref{metricaNuevaTiempo}) se tiene que 

para Ionosphere ha aumentado el tiempo un $1061.021 \%$, para 
Parkinson $578.37 \%$ y finalmente 
Specf heart $1363.056 \%$  

